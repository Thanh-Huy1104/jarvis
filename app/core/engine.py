import logging
import time
from typing import Literal
from functools import partial

# LangGraph & LangChain Imports
from langgraph.graph import StateGraph, END, START
from langgraph.checkpoint.memory import MemorySaver

# Internal Imports
from app.core.state import AgentState
from app.core.router import JarvisRouter
from app.core.skills import SkillLibrary
from app.core import nodes
from app.core.utils import cleanup_engine, log_timing_report
from app.adapters.llm_vllm import VllmAdapter
from app.adapters.memory_mem0 import Mem0Adapter
from app.execution.sandbox import DockerSandbox

logger = logging.getLogger(__name__)

class JarvisEngine:
    """
    The main Jarvis orchestration engine.
    
    Architecture:
    1. Router (Intent Classification)
    2. Speed Mode OR Complex Mode
    3. If Complex: Context Builder -> Parallel Planner
    4. Parallel Planner -> Sequential Path OR Parallel Path
    5. Execution & Aggregation
    """
    
    def __init__(self):
        # Initialize Adapters
        self.router = JarvisRouter()
        self.llm = VllmAdapter()
        self.memory = Mem0Adapter()
        self.skills = SkillLibrary()
        self.sandbox = DockerSandbox()
        
        # Runtime State
        self._task_callback = None
        self._timing = {}
        
        # Persistence (In-Memory Checkpointer)
        # Must be initialized once to retain history across graph runs
        self.checkpointer = MemorySaver()
        
        logger.info("JarvisEngine initialized with Modular Architecture")

    # =========================================================================
    # ROUTING LOGIC (The "Brain" - Decides where to go)
    # =========================================================================

    def route_query_node(self, state: AgentState) -> dict:
        """Entry Node: Classifies intent (Speed vs Complex)."""
        start_time = time.time()
        
        # Build minimal context for router
        messages = state.get("messages", [])
        context = ""
        if messages:
            recent = messages[-4:]
            context = "\n".join([f"{m.type}: {m.content[:150]}" for m in recent])
        
        intent = self.router.classify(state["user_input"], conversation_context=context)
        
        self._timing['route_query'] = (time.time() - start_time) * 1000
        return {"intent_mode": intent}

    def determine_intent(self, state: AgentState) -> Literal["speed_agent", "context_builder"]:
        """Conditional Edge: Speed vs Thinking Mode"""
        return "speed_agent" if state["intent_mode"] == "speed" else "context_builder"

    def determine_parallelism(self, state: AgentState) -> Literal["parallel_executor", "think_agent"]:
        """
        Conditional Edge: Decides if we execute sequentially or in parallel 
        based on the plan generated by the planner node.
        """
        plan = state.get("plan", [])
        
        # If plan has > 1 subtasks, go parallel. Otherwise, sequential thinking.
        if plan and len(plan) > 1:
            logger.info(f"→ Routing to PARALLEL execution ({len(plan)} tasks)")
            return "parallel_executor"
        
        logger.info("→ Routing to SEQUENTIAL execution")
        return "think_agent"

    def check_research_type(self, state: AgentState) -> Literal["iterative_research", "executor"]:
        """
        Conditional Edge: Checks if the task needs iterative research
        (multi-step tool calls) or single code execution.
        """
        # Check if task requires deep research (news, web search, analysis)
        user_input = state.get("user_input", "").lower()
        research_keywords = ["news", "search", "find information", "tell me about", "what is", "research"]
        
        if any(keyword in user_input for keyword in research_keywords):
            logger.info("→ Routing to ITERATIVE RESEARCH (multi-step)")
            return "iterative_research"
        
        # If code was generated, use single execution
        code = state.get("generated_code", "")
        if code and code.strip():
            logger.info("→ Routing to SANDBOX executor (code generated)")
            return "executor"
        
        # Default to executor
        logger.info("→ Routing to SANDBOX executor (default)")
        return "executor"

    # =========================================================================
    # GRAPH CONSTRUCTION
    # =========================================================================

    def build(self):
        """Builds the LangGraph StateGraph."""
        workflow = StateGraph(AgentState)
        
        # --- Add Nodes ---
        # Use functools.partial to bind 'self' to node functions
        
        # 1. Classification
        workflow.add_node("router", self.route_query_node)
        
        # 2a. Speed Path (async)
        workflow.add_node("speed_agent", partial(nodes.speed_response, self))
        
        # 2b. Complex Path (Context -> Plan) (async)
        workflow.add_node("context_builder", partial(nodes.build_context, self))
        workflow.add_node("parallel_planner", partial(nodes.plan_parallel_tasks, self))
        
        # 3a. Sequential Path (Think -> Execute) (async for think, sync for executor)
        workflow.add_node("think_agent", partial(nodes.reason_and_code, self))
        workflow.add_node("executor", partial(nodes.execute_code, self))
        workflow.add_node("iterative_research", partial(nodes.iterative_research, self))
        
        # 3b. Parallel Path (Execute Workers & Aggregate) (async)
        # Note: aggregate_parallel_results handles the concurrent worker execution internally
        workflow.add_node("parallel_executor", partial(nodes.aggregate_parallel_results, self))
        
        # 4. Final Save (Admin) (sync)
        workflow.add_node("admin_save", partial(nodes.admin_approval, self))

        # --- Add Edges ---
        
        # Start -> Router
        workflow.add_edge(START, "router")
        
        # Router -> Split (Speed vs Complex)
        workflow.add_conditional_edges(
            "router",
            self.determine_intent,
            {
                "speed_agent": "speed_agent",
                "context_builder": "context_builder"
            }
        )
        
        # Complex Path: Context -> Planner
        workflow.add_edge("context_builder", "parallel_planner")
        
        # Planner -> Split (Parallel vs Sequential)
        workflow.add_conditional_edges(
            "parallel_planner",
            self.determine_parallelism,
            {
                "parallel_executor": "parallel_executor",
                "think_agent": "think_agent"
            }
        )
        
        # Sequential Path Logic: Think -> (Check Research Type) -> Execute
        workflow.add_conditional_edges(
            "think_agent",
            self.check_research_type,
            {
                "executor": "executor",
                "iterative_research": "iterative_research"
            }
        )
        
        # Execution Outcomes
        workflow.add_edge("executor", "admin_save")
        workflow.add_edge("iterative_research", "admin_save")
        workflow.add_edge("admin_save", END)
        
        # Parallel Outcome
        workflow.add_edge("parallel_executor", END)
        
        # Speed Outcome
        workflow.add_edge("speed_agent", END)

        # Compile with persistent checkpointer
        return workflow.compile(checkpointer=self.checkpointer)

    # =========================================================================
    # UTILITIES
    # =========================================================================

    async def cleanup(self):
        """Cleanup resources."""
        pass
    
    def report_timing(self):
        """Log execution timing and reset."""
        log_timing_report(self._timing)
        self._timing = {}  # Reset for next request